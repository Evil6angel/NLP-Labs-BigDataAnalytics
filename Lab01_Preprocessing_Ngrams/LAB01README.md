# Lab 01 – Preprocessing, Minimum Edit Distance & N-grams

- Text processing: tokenization, stopword removal, stemming (Porter vs. Lancaster) and lemmatization (with brief compare/when-to-use).
- Minimum Edit Distance (MED): manual DP walkthrough on given pairs + your own implementation tested on an intentionally misspelled word.
- N-gram modeling (on the Kaggle Twitter file): sentence tokenization, vocab with threshold & <UNK>, n-gram counts, count table → Laplace-smoothed probability table.

## Tech: Python, NLTK, Pandas, NumPy